<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" >

<head>

<style type="text/css">
h1
{
margin-top: 0;
margin-bottom: 0;
}
h3
{
margin-top: 0;
margin-bottom: 0;
}
body
{
color: #000000;
background: #FDFEFE;
}
a:link { 
color: #264889;
text-decoration: none;
}
a:visited { 
color: #264889;
}
a:hover { 
color: #117A65;
text-decoration: none;
}
a:active { 
color: #74AFAD;
}
sup {
    vertical-align: super;
    font-size: smaller;
}
</style>


<title>Arash Tavakoli</title>

</head>
<body>

<center>
<table>
<tr>
<td style="width: 740px" valign=top align=left>

<table cellpadding=5px>
<tr>
<td valign=top>

<img src="images/aureche.png" alt="Arash Tavakoli" height="252" border=0/>

</td>
<td align=left valign=top width=100%>
<a id="top"></a>
<h1>Arash Tavakoli</h1><br>

PhD Student in Reinforcement Learning<br><br>

Imperial College London<br>
1<sup>st</sup> Floor, Observatory Building<br>
South Kensington, London SW7 2AZ<br><br>

<TT>a.tavakoli</TT> [at] <TT>imperial.ac.uk</TT><br><br>
<a href="https://twitter.com/arshtvk"><img src="images/twitter-circ.png" alt="twitter" height="60"/></a>
<a href="https://github.com/atavakol"><img src="images/github-circ.png" alt="github" height="60"/></a>
<a href="https://www.linkedin.com/in/arashtavakoli/"><img src="images/linkedin-circ.png" alt="linkedin" height="60"/></a>
<a href="https://scholar.google.co.uk/citations?user=Jwq-Qx0AAAAJ&hl=en&oi=ao"><img src="images/google-scholar-circ.png" alt="google scholar" height="60"/></a>
</dl>

</td>
</tr>
</table>

<!--p align=justify>
I am a PhD student in Machine Learning at the Imperial College London. My research mainly revolves around deep reinforcement learning, focusing on creating novel ways of combining deep learning with reinforcement learning to take steps towards solving challenging problems in artificial intelligence.
</p-->

<body>
    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>News</h2>
            <ul>
            	<li>
                    <b>May 2018:</b> Paper accepted for publication at the <a href="https://icml.cc/">35th Int. Conf. on Machine Learning</a> (<b>ICML 2018</b>):<br> 
                        &rarr; <b>Time Limits in Reinforcement Learning</b> [<a href="papers/ICML-2018.pdf">PDF</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">videos & code</a>]
                </li><br>

                <li>
                    <b>Apr 2018:</b> Delighted to have been invited to attend the <a href="https://dlrlsummerschool.ca/">Deep Learning & Reinforcement Learning Summer Schools</a> (hosted by <b>CIFAR</b> and <b>Vector Institute</b>, with participation and support from <b>Amii</b> and <b>MILA</b>) to be held in Toronto, Canada.
                </li><br>

            	<li>
                    <b>Feb 2018:</b> I gave a talk at the <a href="https://aaai.org/Conferences/AAAI-18/">32nd AAAI Conf. on Artificial Intelligence</a> (<b>AAAI 2018</b>):
                    [<a href="https://youtu.be/u0dCuln_a-Q">video</a> | <a href="talks/AAAI-2018-slides.pdf">slides</a>]<br>
                    
                </li><br>

                <li>
                    <b>Nov 2017:</b> Two papers accepted for presentation at the <a href="https://sites.google.com/view/deeprl-symposium-nips2017/">Deep Reinforcement Learning Symposium</a>, <a href="https://nips.cc/Conferences/2017/">31st Conf. on Neural Information Processing Systems</a> (<b>NIPS 2017</b>):<br>
                        &rarr; <b>Time Limits in Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-2.pdf">poster</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">videos & code</a>]<br>

                        &rarr; <b>Action Branching Architectures for Deep Reinforcement Learning</b> [<a href="posters/NIPS-2017-DRLS-poster-1.pdf">poster</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]   
                </li><br>

                <li>
                    <b>Nov 2017:</b> Paper accepted for publication at the <a href="https://aaai.org/Conferences/AAAI-18/">32nd AAAI Conf. on Artificial Intelligence</a> (<b>AAAI 2018</b>):<br> 
                        &rarr; <b>Action Branching Architectures for Deep Reinforcement Learning</b> [<a href="papers/AAAI-2018.pdf">PDF</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]
                </li><br>
                
                <li>
                    <b>Sep 2017:</b> I attended the <a href="http://www.deeplearningindaba.com/2017.html">Deep Learning Indaba</a> (organized by <b>DeepMind</b>) in Johannesburg, South Africa.
                </li><br>

                <li>
                    <b>Aug 2017:</b> I passed my first official PhD milestone with <a href="http://www.szit.bme.hu/~gya/">András György</a> as my examiner.
                </li>
            </ul>
        </div>
    </div>

    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>Education</h2>
            <ul>
                <li>
                    <b>2014 – 2016:</b><br><ul>
                        <li>MSc in Computer Science</li>
                        <li>University of Southern California (<b>USC</b>), Los Angeles, California, USA</li>
                </ul></li>

                <li>
                    <b>2010 – 2014:</b><br><ul>
                        <li>MEng in Electrical Engineering</li>
                        <li>University College London (<b>UCL</b>), London, UK</li>
                </ul></li>

                <li>
                    <b>2012 – 2013:</b><br><ul>
                        <li>Exchange Student in Electrical and Computer Engineering</li>
                        <li>Georgia Institute of Technology (<b>Georgia Tech</b>), Atlanta, Georgia, USA</li>
                </ul></li>
            </ul>
        </div>
    </div>

    <div class="row">
        <div class="col-md-4 col-md-offset-4">
            <h2>Representative Publications</h2>
            <ul>
                <li>
                    <b>Action Branching Architectures for Deep Reinforcement Learning</b> <br>
                    <b>Arash Tavakoli</b>, Fabio Pardo, Petar Kormushev <br>
                    In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (<b>AAAI</b>)<br> New Orleans, Louisiana, USA, 2018.
                    <br>
                    [<a href="papers/AAAI-2018.pdf">PDF</a> | <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17222">AAAI Library</a> | <a href="https://arxiv.org/abs/1711.08946">arXiv</a> | <a href="https://github.com/atavakol/action-branching-agents">code</a>]
                </li><br>

                <li>
                    <b>Time Limits in Reinforcement Learning</b> <br>
                    Fabio Pardo, <b>Arash Tavakoli</b>, Vitaly Levdik, Petar Kormushev <br>
                    In Proceedings of the 35th International Conference on Machine Learning (<b>ICML</b>)<br> Stockholm, Sweden, 2018.
                    <br>
                    [<a href="papers/ICML-2018.pdf">PDF</a> | <a href="http://proceedings.mlr.press/v80/pardo18a.html">PMLR Library</a> | <a href="https://arxiv.org/abs/1712.00378">arXiv</a> | <a href="https://sites.google.com/view/time-limits-in-rl">videos & code</a>]
                </li><br>
            </ul>
        </div>
    </div>
 
    <!-- /.container -->

    <!-- jQuery -->
    <!--script src="js/jquery.js"></script-->

    <!-- Bootstrap Core JavaScript -->
    <!--script src="js/bootstrap.min.js"></script-->

</body>

</html>
